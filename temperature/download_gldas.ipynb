{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLDAS Temperature Download\n",
    "\n",
    "Goals:\n",
    "\n",
    "1. For each SWC station, pull GLDAS 2.0 results for the given coordinate location between 1990 and 1999.\n",
    "2. For each SWC station, pull GLDAS 2.1 results for the given coordinate location between 2000 and 2020.\n",
    "3. Aggregate results together into CSV file excluding no results (-9999) stations\n",
    "4. For SWC stations with no results (-9999), check nearest neighboring grids for results.\n",
    "5. If found, pull GLDAS 2.0 results for neighboring grid between 1990 and 1999.\n",
    "6. If found, pull GLDAS 2.1 results for neighboring grid between 2000 and 2020.\n",
    "7. Aggregate results together into near CSV file.\n",
    "\n",
    "General Statistics:\n",
    "\n",
    "* Total Stations: 5144\n",
    "* Stations with GLDAS grid information: 4765\n",
    "* Stations with neighboring GLDAS grid information: 318\n",
    "* Stations with no GLDAS information: 61\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Total time to download and process GLDAS is about 5 or 6 days of 24-7 single thread downloading.\n",
    "\n",
    "* GLDAS uses a \"backwards three-hour average\" for temperature making querying by date a tad tricky.  For example, the final three hours of the UTC-defined day are stored under the timestamp for midnight the following day.   Some care and attention is needed to make sure the values are assigned to the proper day max and min.\n",
    "\n",
    "* The GLDAS servers will occasionally throw one of several kinds of errors.  The most common is the \"bad rods\" response.  When the server returns this error things are usually in a precarious state and its best to give it a rest and return to the downloads later.  The other error is an HTTP result proclaiming an ERROR has occurred.  And the final problem is the most insidious, when results are summarily truncated with no warning.  For example, a GLDAS 2.0 call might just stop at 1997.  The notebook logic verifies that each results returns the final day of the set.\n",
    "\n",
    "* The logic to search for neighboring grids with data creates a global 0.25 degree grid coverage and determines the nearest of the eight neighboring grids to the station location.  Then the grids are checked in order for results taking the closest grid with data.  All eight neighbor grids are checked.  Note the burden to query so many neighbor grids for the 318 locations means the grid9999 processing step takes about 6 hours to complete.\n",
    "\n",
    "* As we assume a difference in quality between location under a grid and locations nearby to a grid, we store the results as two separate categories, **gldas** and **gldasnear**.  The difference may not matter to the final SWC product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy;\n",
    "import os,sys;\n",
    "import requests;\n",
    "import datetime;\n",
    "from time import sleep;\n",
    "\n",
    "start_date  = datetime.datetime(1990,1,1)   + datetime.timedelta(hours=3);\n",
    "end_date    = datetime.datetime(2020,12,31) + datetime.timedelta(hours=24);\n",
    "target_csv  = 'gldas_20210822.csv';\n",
    "target_near = 'gldasnear_20210822.csv';\n",
    "\n",
    "results_fgdb = os.getcwd() + os.sep + '..'+ os.sep + 'results.gdb';\n",
    "target_dir   = os.getcwd() + os.sep + 'gldas';\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.mkdir(target_dir);\n",
    "\n",
    "stations = results_fgdb  + os.sep + 'SWC_Station_Universe';\n",
    "stations_cnt = arcpy.GetCount_management(stations)[0];\n",
    "print(\"  Initial SWC Station Universe Count: \" + str(stations_cnt));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "raw_files_dir = target_dir + os.sep + 'raw';\n",
    "\n",
    "if not os.path.exists(raw_files_dir):\n",
    "    os.mkdir(raw_files_dir);\n",
    "\n",
    "with arcpy.da.SearchCursor(\n",
    "     in_table     = results_fgdb + os.sep + 'SWC_Station_Universe'\n",
    "    ,field_names  = ['StationId','SHAPE@']\n",
    "    ,sql_clause=(None, \"ORDER BY StationID ASC\")\n",
    ") as incur:\n",
    "\n",
    "    for row in incur:\n",
    "        \n",
    "        point = row[1].firstPoint;\n",
    "        lat  = round(point.Y,8);\n",
    "        lon  = round(point.X,8);\n",
    "        name = row[0];\n",
    "        \n",
    "        target_20 = raw_files_dir + os.sep + name + '_gldas20.txt';\n",
    "        target_21 = raw_files_dir + os.sep + name + '_gldas21.txt';\n",
    "        \n",
    "        if not os.path.exists(target_20):\n",
    "                \n",
    "            url = \"https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/\"   \\\n",
    "                + \"access/timeseries.cgi\"                              \\\n",
    "                + \"?variable=GLDAS2:GLDAS_NOAH025_3H_v2.0:Tair_f_inst\" \\\n",
    "                + \"&startDate=\" + start_date.strftime(\"%Y-%m-%dT%H\")   \\\n",
    "                + \"&endDate=2000-01-01T00\"                             \\\n",
    "                + \"&location=GEOM:POINT(\" + str(lon) + \",%20\" + str(lat) + \")\" \\\n",
    "                + \"&type=asc2\";  \n",
    "        \n",
    "            boo_good_2000 = False;\n",
    "            boo_good = True;\n",
    "            with open(target_20,'wb') as f:\n",
    "\n",
    "                with requests.get(\n",
    "                     url\n",
    "                    ,stream = True\n",
    "                ) as r:\n",
    "                    for line in r.iter_lines():\n",
    "                        if line[0:6] == b'ERROR:':\n",
    "                            boo_good = False;\n",
    "                            break;\n",
    "                        \n",
    "                        if line[0:19] == b'2000-01-01T00:00:00':\n",
    "                            boo_good_2000 = True;\n",
    "                            \n",
    "                        f.write(line+'\\n'.encode());\n",
    "                        \n",
    "            if not boo_good:\n",
    "                print(\"bad rods 20 for \" + name + \", skipping for now\");\n",
    "                sleep(2);\n",
    "                os.remove(target_20);\n",
    "                \n",
    "            elif not boo_good_2000:\n",
    "                print(\"partial data 20 received for \" + name + \", skipping for now\");\n",
    "                sleep(2);\n",
    "                os.remove(target_20);\n",
    "          \n",
    "        if not os.path.exists(target_21):\n",
    "            \n",
    "            url = \"https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/\"   \\\n",
    "                + \"access/timeseries.cgi\"                              \\\n",
    "                + \"?variable=GLDAS2:GLDAS_NOAH025_3H_v2.1:Tair_f_inst\" \\\n",
    "                + \"&startDate=1999-12-31T00\"                           \\\n",
    "                + \"&endDate=\" + end_date.strftime(\"%Y-%m-%dT%H\")       \\\n",
    "                + \"&location=GEOM:POINT(\" + str(lon) + \",%20\" + str(lat) + \")\" \\\n",
    "                + \"&type=asc2\"; \n",
    "            \n",
    "            boo_good_2020 = False;\n",
    "            boo_good = True;\n",
    "            with open(target_21,'wb') as f:\n",
    "\n",
    "                with requests.get(\n",
    "                     url\n",
    "                    ,stream = True\n",
    "                ) as r:\n",
    "                    for line in r.iter_lines():\n",
    "                        if line[0:6] == b'ERROR:':\n",
    "                            boo_good = False;\n",
    "                            break;\n",
    "                            \n",
    "                        if line[0:19] == b'2020-12-31T21:00:00':\n",
    "                            boo_good_2020 = True;\n",
    "                            \n",
    "                        f.write(line+'\\n'.encode());\n",
    "                        \n",
    "            if not boo_good:\n",
    "                print(\"bad rods 21 for \" + name + \", skipping for now\");\n",
    "                sleep(2);\n",
    "                os.remove(target_21);\n",
    "                \n",
    "            elif not boo_good_2020:\n",
    "                print(\"partial data 21 received for \" + name + \", skipping for now\");\n",
    "                sleep(2);\n",
    "                os.remove(target_21);\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = target_dir + os.sep + target_csv;\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    os.remove(target_file);\n",
    "\n",
    "with arcpy.da.SearchCursor(\n",
    "     in_table     = results_fgdb + os.sep + 'SWC_Station_Universe'\n",
    "    ,field_names  = ['StationId']\n",
    ") as incur:\n",
    "    \n",
    "    with open(target_file,'w') as outcur:\n",
    "    \n",
    "        for row in incur:\n",
    "            name = row[0];\n",
    "            \n",
    "            source_file20 = raw_files_dir + os.sep + name + '_gldas20.txt';\n",
    "            with open(source_file20,'r') as f20:\n",
    "\n",
    "                writeit20 = False;\n",
    "                for line in f20:\n",
    "                    \n",
    "                    if writeit20 and len(line) > 0:\n",
    "                        (dtin20,tpin20) = line.split('\\t');\n",
    "                        dt20  = datetime.datetime.strptime(dtin20,\"%Y-%m-%dT%H:%M:%S\");\n",
    "                        tpk20 = float(tpin20) ;\n",
    "                        \n",
    "                        if tpk20 > 0:\n",
    "                            tpf20 = (tpk20 - 273.15) * 1.8000 + 32.00;\n",
    "\n",
    "                            outcur.write('\"' + name + '\",\"' + str(dt20) + '\",' + str(round(tpf20,8)) + '\\n');\n",
    "                            \n",
    "                    if line == 'Date&Time               Data\\n':\n",
    "                        writeit20 = True;\n",
    "                        \n",
    "            source_file21 = raw_files_dir + os.sep + name + '_gldas21.txt';\n",
    "            with open(source_file21,'r') as f21:\n",
    "\n",
    "                writeit21 = False;\n",
    "                for line in f21:\n",
    "\n",
    "                    if writeit21 and len(line) > 0:\n",
    "                        (dtin21,tpin21) = line.split('\\t');\n",
    "                        dt21  = datetime.datetime.strptime(dtin21,\"%Y-%m-%dT%H:%M:%S\");\n",
    "                        tpk21 = float(tpin21) ;\n",
    "                        \n",
    "                        if tpk21 > 0:\n",
    "                            tpf21 = (tpk21 - 273.15) * 1.8000 + 32.00;\n",
    "\n",
    "                            outcur.write('\"' + name + '\",\"' + str(dt21) + '\",' + str(round(tpf21,8)) + '\\n');\n",
    "                            \n",
    "                    if line == 'Date&Time               Data\\n':\n",
    "                        writeit21 = True;\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station20_9999s = [];\n",
    "station21_9999s = [];\n",
    "\n",
    "raw_files_dir = target_dir + os.sep + 'raw';\n",
    "gldas9999_fc = results_fgdb + os.sep + 'gldas_9999';\n",
    "\n",
    "if arcpy.Exists(gldas9999_fc):\n",
    "    arcpy.Delete_management(gldas9999_fc);\n",
    "    \n",
    "arcpy.CreateFeatureclass_management(\n",
    "     out_path      = os.path.dirname(gldas9999_fc)\n",
    "    ,out_name      = os.path.basename(gldas9999_fc)\n",
    "    ,geometry_type = \"POINT\"\n",
    "    ,has_m         = \"DISABLED\"\n",
    "    ,has_z         = \"DISABLED\"\n",
    "    ,spatial_reference = arcpy.SpatialReference(4269) \n",
    ");\n",
    "\n",
    "arcpy.management.AddFields(\n",
    "     in_table          = gldas9999_fc\n",
    "    ,field_description = [\n",
    "         ['stationId'       ,'TEXT'  ,'Station ID'       ,255]\n",
    "    ]\n",
    ");\n",
    "\n",
    "arcpy.management.AddIndex(\n",
    "     in_table   = gldas9999_fc\n",
    "    ,fields     = 'StationId'\n",
    "    ,index_name = 'StationId_IDX'\n",
    ");\n",
    "\n",
    "with arcpy.da.SearchCursor(\n",
    "     in_table     = results_fgdb + os.sep + 'SWC_Station_Universe'\n",
    "    ,field_names  = ['StationId']\n",
    ") as incur:\n",
    "    \n",
    "    for row in incur:\n",
    "        name = row[0];\n",
    "\n",
    "        source_file20 = raw_files_dir + os.sep + name + '_gldas20.txt';\n",
    "        with open(source_file20,'r') as f20:\n",
    "\n",
    "            writeit20 = False;\n",
    "            for line in f20:\n",
    "\n",
    "                if writeit20 and len(line) > 0:\n",
    "                    (dtin20,tpin20) = line.split('\\t');\n",
    "                    tpk20 = float(tpin20) ;\n",
    "\n",
    "                    if tpk20 == -9999:\n",
    "                        station20_9999s.append(name);\n",
    "                    \n",
    "                    break;\n",
    "\n",
    "                if line == 'Date&Time               Data\\n':\n",
    "                    writeit20 = True;\n",
    "                    \n",
    "        source_file21 = raw_files_dir + os.sep + name + '_gldas21.txt';\n",
    "        with open(source_file21,'r') as f21:\n",
    "\n",
    "            writeit21 = False;\n",
    "            for line in f21:\n",
    "\n",
    "                if writeit21 and len(line) > 0:\n",
    "                    (dtin21,tpin21) = line.split('\\t');\n",
    "                    tpk21 = float(tpin21) ;\n",
    "\n",
    "                    if tpk21 == -9999:\n",
    "                        station21_9999s.append(name);\n",
    "                        \n",
    "                    break;\n",
    "\n",
    "                if line == 'Date&Time               Data\\n':\n",
    "                    writeit21 = True;\n",
    "                        \n",
    "if len(station20_9999s) != len(station21_9999s):\n",
    "    raise Exception('9999 counts do not match between 2.0 and 2.1');\n",
    "    \n",
    "with arcpy.da.SearchCursor(\n",
    "     in_table     = results_fgdb + os.sep + 'SWC_Station_Universe'\n",
    "    ,field_names  = ['StationId','SHAPE@']\n",
    "    ,sql_clause=(None, \"ORDER BY StationID ASC\")\n",
    ") as incur:\n",
    "    \n",
    "    with arcpy.da.InsertCursor(\n",
    "         in_table     = gldas9999_fc\n",
    "        ,field_names  = ['StationId','SHAPE@']\n",
    "    ) as outcur:\n",
    "\n",
    "        for row in incur:\n",
    "            name = row[0];\n",
    "\n",
    "            if name in station20_9999s:\n",
    "\n",
    "                outcur.insertRow((\n",
    "                     row[0]\n",
    "                    ,row[1]\n",
    "                ));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gldas_grid_fc = results_fgdb + os.sep + 'gldas_grid';\n",
    "\n",
    "if arcpy.Exists(gldas_grid_fc):\n",
    "    arcpy.Delete_management(gldas_grid_fc);\n",
    "\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(4269);\n",
    "arcpy.cartography.GridIndexFeatures(\n",
    "     out_feature_class = gldas_grid_fc\n",
    "    ,polygon_width     = '0.25 degree'\n",
    "    ,polygon_height    = '0.25 degree' \n",
    "    ,origin_coord      = '-180, -90'\n",
    "    ,number_rows       = 720\n",
    "    ,number_columns    = 1440\n",
    ");\n",
    "\n",
    "arcpy.management.AddFields(\n",
    "     in_table          = gldas_grid_fc\n",
    "    ,field_description = [\n",
    "         ['centroidX'       ,'DOUBLE'  ,'Centroid X'     ]\n",
    "        ,['centroidY'       ,'DOUBLE'  ,'Centroid Y'     ]\n",
    "    ]\n",
    ");\n",
    "\n",
    "with arcpy.da.UpdateCursor(\n",
    "     in_table     = gldas_grid_fc\n",
    "    ,field_names  = ['SHAPE@TRUECENTROID','centroidX','centroidY']\n",
    ") as cursor:\n",
    "    \n",
    "    for row in cursor:\n",
    "        \n",
    "        (ptx,pty) = row[0];\n",
    "        \n",
    "        row[1] = ptx;\n",
    "        row[2] = pty;\n",
    "        \n",
    "        cursor.updateRow(row);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gldas_near_tbl = results_fgdb + os.sep + 'gldas9999_near';\n",
    "\n",
    "if arcpy.Exists(gldas_near_tbl):\n",
    "    arcpy.Delete_management(gldas_near_tbl);\n",
    "\n",
    "arcpy.analysis.GenerateNearTable(\n",
    "     in_features   = gldas9999_fc\n",
    "    ,near_features = gldas_grid_fc\n",
    "    ,out_table     = gldas_near_tbl\n",
    "    ,search_radius = '0.25 degree'\n",
    "    ,closest       = 'ALL'\n",
    "    ,closest_count = 9\n",
    "    ,method        = 'GEODESIC'\n",
    ");\n",
    "\n",
    "arcpy.management.JoinField(\n",
    "     in_data    = gldas_near_tbl\n",
    "    ,in_field   = 'NEAR_FID'\n",
    "    ,join_table = gldas_grid_fc\n",
    "    ,join_field = 'OID'\n",
    "    ,fields     = ['centroidX','centroidY']\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "raw_files_dir = target_dir + os.sep + 'raw';\n",
    "gldas9999_fc = results_fgdb + os.sep + 'gldas_9999';\n",
    "gldas_near_tbl = results_fgdb + os.sep + 'gldas9999_near';\n",
    "raw9999_files_dir = target_dir + os.sep + 'raw9999';\n",
    "\n",
    "if not os.path.exists(raw9999_files_dir):\n",
    "    os.mkdir(raw9999_files_dir);\n",
    "\n",
    "with arcpy.da.SearchCursor(\n",
    "     in_table     = gldas9999_fc\n",
    "    ,field_names  = ['ObjectID','StationId']\n",
    "    ,sql_clause=(None, \"ORDER BY StationID ASC\")\n",
    ") as incur:\n",
    "    \n",
    "    for outer_row in incur:\n",
    "        src_fid = outer_row[0];\n",
    "        name    = outer_row[1];\n",
    "        target_20 = raw9999_files_dir + os.sep + name + '_gldas20.txt';\n",
    "        target_21 = raw9999_files_dir + os.sep + name + '_gldas21.txt';\n",
    "        \n",
    "        if not os.path.exists(target_20) or not os.path.exists(target_21):\n",
    "            \n",
    "            with arcpy.da.SearchCursor(\n",
    "                 in_table     = gldas_near_tbl\n",
    "                ,field_names  = ['IN_FID','NEAR_FID','NEAR_DIST','NEAR_RANK','centroidX','centroidY']\n",
    "                ,sql_clause=(None, \"ORDER BY NEAR_RANK ASC\")\n",
    "                ,where_clause = 'IN_FID = ' + str(src_fid) + ' AND NEAR_RANK > 1'\n",
    "            ) as nearcur:\n",
    "\n",
    "                boo_results = False;\n",
    "                for inner_row in nearcur:\n",
    "\n",
    "                    gridX = inner_row[4];\n",
    "                    gridY = inner_row[5];\n",
    "                    rank  = inner_row[3];\n",
    "                    dist  = inner_row[2];\n",
    "                    dist_msg = 'grid_distance=' + str(dist) + '\\n';\n",
    "                    \n",
    "                    url = \"https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/\"   \\\n",
    "                        + \"access/timeseries.cgi\"                              \\\n",
    "                        + \"?variable=GLDAS2:GLDAS_NOAH025_3H_v2.0:Tair_f_inst\" \\\n",
    "                        + \"&startDate=\" + start_date.strftime(\"%Y-%m-%dT%H\")   \\\n",
    "                        + \"&endDate=2000-01-01T00\"                             \\\n",
    "                        + \"&location=GEOM:POINT(\" + str(gridX) + \",%20\" + str(gridY) + \")\" \\\n",
    "                        + \"&type=asc2\";  \n",
    "\n",
    "                    with requests.get(\n",
    "                         url\n",
    "                        ,stream = True\n",
    "                    ) as r:\n",
    "                        for line in r.iter_lines():\n",
    "                            \n",
    "                            if line[0:6] == b'ERROR:':\n",
    "                                raise Exception('bad results for ' + name);\n",
    "                                \n",
    "                            str_line = str(line,'utf-8').strip();\n",
    "\n",
    "                            val = None;\n",
    "                            if str_line.find('\\t') > 0:\n",
    "                                (dt,val) = str_line.split('\\t');\n",
    "                                                               \n",
    "                            if val is not None and float(val) > 0:\n",
    "                                boo_results = True;\n",
    "                                break;\n",
    "\n",
    "                        if boo_results:\n",
    "                            break;\n",
    "\n",
    "            if boo_results:\n",
    "\n",
    "                url = \"https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/\"   \\\n",
    "                    + \"access/timeseries.cgi\"                              \\\n",
    "                    + \"?variable=GLDAS2:GLDAS_NOAH025_3H_v2.0:Tair_f_inst\" \\\n",
    "                    + \"&startDate=\" + start_date.strftime(\"%Y-%m-%dT%H\")   \\\n",
    "                    + \"&endDate=2000-01-01T00\"                             \\\n",
    "                    + \"&location=GEOM:POINT(\" + str(gridX) + \",%20\" + str(gridY) + \")\" \\\n",
    "                    + \"&type=asc2\";\n",
    "\n",
    "                boo_good_2000 = False;\n",
    "                with open(target_20,'wb') as f:\n",
    "                    f.write(dist_msg.encode('utf-8'));\n",
    "                    \n",
    "                    with requests.get(\n",
    "                         url\n",
    "                        ,stream = True\n",
    "                    ) as r:\n",
    "                        for line in r.iter_lines():\n",
    "\n",
    "                            if line[0:6] == b'ERROR:':\n",
    "                                raise Exception('bad 20 results for ' + name);\n",
    "\n",
    "                            if line[0:19] == b'2000-01-01T00:00:00':\n",
    "                                boo_good_2000 = True;\n",
    "\n",
    "                            f.write(line+'\\n'.encode());\n",
    "\n",
    "                if not boo_good_2000:\n",
    "                    raise Exception('bad 20 results for ' + name);\n",
    "\n",
    "                url = \"https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/\"   \\\n",
    "                    + \"access/timeseries.cgi\"                              \\\n",
    "                    + \"?variable=GLDAS2:GLDAS_NOAH025_3H_v2.1:Tair_f_inst\" \\\n",
    "                    + \"&startDate=1999-12-31T00\"                           \\\n",
    "                    + \"&endDate=\" + end_date.strftime(\"%Y-%m-%dT%H\")       \\\n",
    "                    + \"&location=GEOM:POINT(\" + str(gridX) + \",%20\" + str(gridY) + \")\" \\\n",
    "                    + \"&type=asc2\"; \n",
    "\n",
    "                boo_good_2020 = False;\n",
    "                with open(target_21,'wb') as f:\n",
    "                    f.write(dist_msg.encode('utf-8'));\n",
    "\n",
    "                    with requests.get(\n",
    "                         url\n",
    "                        ,stream = True\n",
    "                    ) as r:\n",
    "                        for line in r.iter_lines():\n",
    "\n",
    "                            if line[0:6] == b'ERROR:':\n",
    "                                raise Exception('bad 21 results for ' + name);\n",
    "\n",
    "                            if line[0:19] == b'2020-12-31T21:00:00':\n",
    "                                boo_good_2020 = True;\n",
    "\n",
    "                            f.write(line+'\\n'.encode());\n",
    "\n",
    "                if not boo_good_2020:\n",
    "                    raise Exception('bad results for ' + name);\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = target_dir + os.sep + target_near;\n",
    "raw9999_files_dir = target_dir + os.sep + 'raw9999';\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    os.remove(target_file);\n",
    "\n",
    "with arcpy.da.SearchCursor(\n",
    "     in_table     = gldas9999_fc\n",
    "    ,field_names  = ['StationId']\n",
    ") as incur:\n",
    "    \n",
    "    with open(target_file,'w') as outcur:\n",
    "    \n",
    "        for row in incur:\n",
    "            name = row[0];\n",
    "            \n",
    "            source_file20 = raw9999_files_dir + os.sep + name + '_gldas20.txt';\n",
    "            source_file21 = raw9999_files_dir + os.sep + name + '_gldas21.txt';\n",
    "            \n",
    "            if os.path.exists(source_file20):\n",
    "                \n",
    "                with open(source_file20,'r') as f20:\n",
    "\n",
    "                    grid_distance = None;\n",
    "                    lat = None;\n",
    "                    lon = None;\n",
    "                    writeit20 = False;\n",
    "                    for line in f20:\n",
    "\n",
    "                        if line[0:14] == 'grid_distance=':\n",
    "                            grid_distance = float(line[14:]);\n",
    "\n",
    "                        elif line[0:4] == 'lat=':\n",
    "                            lat = float(line[4:]);\n",
    "\n",
    "                        elif line[0:4] == 'lon=':\n",
    "                            lon = float(line[4:]);\n",
    "\n",
    "                        elif writeit20 and len(line) > 0:\n",
    "                            (dtin20,tpin20) = line.split('\\t');\n",
    "                            dt20  = datetime.datetime.strptime(dtin20,\"%Y-%m-%dT%H:%M:%S\");\n",
    "                            tpk20 = float(tpin20) ;\n",
    "\n",
    "                            if tpk20 > 0:\n",
    "                                tpf20 = (tpk20 - 273.15) * 1.8000 + 32.00;\n",
    "\n",
    "                                outcur.write('\"' + name + '\",\"' + str(dt20) + '\",' + str(round(tpf20,8)) \\\n",
    "                                    + ',' + str(round(grid_distance,2)) + ',' + str(lon) + ',' + str(lat) + '\\n');\n",
    "\n",
    "                        if line == 'Date&Time               Data\\n':\n",
    "                            writeit20 = True;\n",
    "\n",
    "                with open(source_file21,'r') as f21:\n",
    "\n",
    "                    grid_distance = None;\n",
    "                    lat = None;\n",
    "                    lon = None;\n",
    "                    writeit21 = False;\n",
    "                    for line in f21:\n",
    "\n",
    "                        if line[0:14] == 'grid_distance=':\n",
    "                            grid_distance = float(line[14:]);\n",
    "\n",
    "                        elif line[0:4] == 'lat=':\n",
    "                            lat = float(line[4:]);\n",
    "\n",
    "                        elif line[0:4] == 'lon=':\n",
    "                            lon = float(line[4:]);\n",
    "\n",
    "                        elif writeit21 and len(line) > 0:\n",
    "                            (dtin21,tpin21) = line.split('\\t');\n",
    "                            dt21  = datetime.datetime.strptime(dtin21,\"%Y-%m-%dT%H:%M:%S\");\n",
    "                            tpk21 = float(tpin21) ;\n",
    "\n",
    "                            if tpk21 > 0:\n",
    "                                tpf21 = (tpk21 - 273.15) * 1.8000 + 32.00;\n",
    "\n",
    "                                outcur.write('\"' + name + '\",\"' + str(dt21) + '\",' + str(round(tpf21,8)) \\\n",
    "                                    + ',' + str(round(grid_distance,2)) + ',' + str(lon) + ',' + str(lat) + '\\n');\n",
    "\n",
    "                        if line == 'Date&Time               Data\\n':\n",
    "                            writeit21 = True;\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
