{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Gather Source Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy,os,http.client,json,requests;\n",
    "\n",
    "# Verify or Create Source filegeodatabase\n",
    "fgdb = os.getcwd() + os.sep + 'source.gdb';\n",
    "\n",
    "if not arcpy.Exists(fgdb):\n",
    "   arcpy.CreateFileGDB_management(\n",
    "       os.path.dirname(fgdb)\n",
    "      ,os.path.basename(fgdb)\n",
    "   );\n",
    "\n",
    "arcpy.Exists(fgdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_ags(host,path,fgdb,fc):\n",
    "    \n",
    "    if arcpy.Exists(fgdb + os.sep + fc):\n",
    "        arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "    headers = {\"Content-type\": \"application/x-www-form-urlencoded\", \"Accept\": \"text/plain\"};\n",
    "    conn = http.client.HTTPSConnection(host);\n",
    "    conn.request(\"POST\",path,\"f=json\",headers);\n",
    "    response = conn.getresponse();\n",
    "    data = response.read();\n",
    "    json_data = json.loads(data);\n",
    "    if not 'currentVersion' in json_data:\n",
    "        raise ValueError(\"Error, unable to query https://\" + host + path);\n",
    "    extraction_amount = json_data['maxRecordCount'];\n",
    "    where = \"1=1\";\n",
    "    params = \"where={}&returnIdsOnly=true&returnGeometry=false&f=json\".format(where);\n",
    "    conn = http.client.HTTPSConnection(host);\n",
    "    conn.request(\"POST\",path + \"/query\",params,headers);\n",
    "    response = conn.getresponse();\n",
    "    data = response.read();\n",
    "    json_data = json.loads(data);\n",
    "    ary_oid   = sorted(json_data['objectIds']);\n",
    "    oid_name  = json_data['objectIdFieldName'];\n",
    "    oid_count = len(ary_oid);\n",
    "    initial_hit = True;\n",
    "    counter = 0;\n",
    "    while counter <= oid_count - 1:\n",
    "        if counter + extraction_amount > oid_count - 1:\n",
    "            int_max = oid_count - 1;\n",
    "        else:\n",
    "            int_max = counter + extraction_amount - 1;\n",
    "        where = oid_name + ' >= ' + str(ary_oid[counter]) + ' AND ' + oid_name + ' <= ' + str(ary_oid[int_max]);\n",
    "        print(\"  pulling records where \" + where);\n",
    "        fields = \"*\";\n",
    "        params = \"where={}&outFields={}&returnGeometry=true&f=json\".format(where, fields);\n",
    "        conn = http.client.HTTPSConnection(host);\n",
    "        conn.request(\"POST\",path + \"/query\",params,headers);\n",
    "        response = conn.getresponse();\n",
    "        data = response.read(); \n",
    "        json_data = json.loads(data);\n",
    "        ef = arcpy.AsShape(json_data,True);\n",
    "        if initial_hit:\n",
    "            arcpy.management.CopyFeatures(ef,fgdb + os.sep + fc)\n",
    "            initial_hit = False;\n",
    "        else:\n",
    "            arcpy.Append_management(ef,fgdb + os.sep + fc,\"NO_TEST\");\n",
    "        counter += extraction_amount;\n",
    "    conn.close(); \n",
    "    del conn;\n",
    "    print(\"  Scrape complete.\");\n",
    "    return True;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CRWU_CREAT_Grid_Projections from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 2000\n",
      "  pulling records where OBJECTID >= 2001 AND OBJECTID <= 4000\n",
      "  pulling records where OBJECTID >= 4001 AND OBJECTID <= 6000\n",
      "  pulling records where OBJECTID >= 6001 AND OBJECTID <= 8000\n",
      "  pulling records where OBJECTID >= 8001 AND OBJECTID <= 10000\n",
      "  pulling records where OBJECTID >= 10001 AND OBJECTID <= 12000\n",
      "  pulling records where OBJECTID >= 12001 AND OBJECTID <= 14000\n",
      "  pulling records where OBJECTID >= 14001 AND OBJECTID <= 16000\n",
      "  pulling records where OBJECTID >= 16001 AND OBJECTID <= 18000\n",
      "  pulling records where OBJECTID >= 18001 AND OBJECTID <= 20000\n",
      "  pulling records where OBJECTID >= 20001 AND OBJECTID <= 22000\n",
      "  pulling records where OBJECTID >= 22001 AND OBJECTID <= 24000\n",
      "  pulling records where OBJECTID >= 24001 AND OBJECTID <= 24743\n",
      "  Scrape complete.\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Grid_Projections/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Grid_Projections\";\n",
    "\n",
    "if arcpy.Exists(fgdb + os.sep + fc):\n",
    "    arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "\n",
    "z = scrape_ags(host,path,fgdb,fc);\n",
    "\n",
    "arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'CREAT_ID'\n",
    "    ,index_name = 'CREAT_ID_IDX'\n",
    ");\n",
    "\n",
    "arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'GRIDCODE'\n",
    "    ,index_name = 'GRIDCODE_IDX'\n",
    ");\n",
    "\n",
    "print(\"DONE\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CRWU_CREAT_Historic_Climate_Stations from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 2000\n",
      "  pulling records where OBJECTID >= 2001 AND OBJECTID <= 4000\n",
      "  pulling records where OBJECTID >= 4001 AND OBJECTID <= 6000\n",
      "  pulling records where OBJECTID >= 6001 AND OBJECTID <= 8000\n",
      "  pulling records where OBJECTID >= 8001 AND OBJECTID <= 10000\n",
      "  pulling records where OBJECTID >= 10001 AND OBJECTID <= 11165\n",
      "  Scrape complete.\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Historic_Climate_Stations/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Historic_Climate_Stations\";\n",
    "\n",
    "if arcpy.Exists(fgdb + os.sep + fc):\n",
    "    arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "\n",
    "z = scrape_ags(host,path,fgdb,fc);\n",
    "\n",
    "arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'CLIMATE_STATION_PK_ID'\n",
    "    ,index_name = 'CLIMATE_STATION_PK_ID_IDX'\n",
    ");\n",
    "\n",
    "arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'NOAA_STATION_ID'\n",
    "    ,index_name = 'NOAA_STATION_ID_IDX'\n",
    ");\n",
    "\n",
    "print(\"DONE\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadtab(url,filename):\n",
    "    if arcpy.Exists(filename):\n",
    "        arcpy.Delete_management(filename);\n",
    "    print(\"  downloading file\");\n",
    "    with open(filename,'wb') as f,requests.get(url,stream=True) as r:\n",
    "        for line in r.iter_lines():\n",
    "            f.write(line + '\\n'.encode());\n",
    "    return True;\n",
    "    \n",
    "def tab2fc(filename,fgdb,fc,longname,latname,field_mapping=None):\n",
    "    \n",
    "    if arcpy.Exists('memory' + os.sep + 'tempTable'):\n",
    "        arcpy.Delete_management('memory' + os.sep + 'tempTable');\n",
    "  \n",
    "    if arcpy.Exists(fgdb + os.sep + fc):\n",
    "        arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "    \n",
    "    print(\"  loading to table\");\n",
    "    arcpy.TableToTable_conversion(\n",
    "         in_rows       = filename\n",
    "        ,out_path      = 'memory'\n",
    "        ,out_name      = 'tempTable'\n",
    "        ,field_mapping = field_mapping\n",
    "    );\n",
    "    print(\"  converting to NAD83 points\");\n",
    "    arcpy.management.XYTableToPoint(\n",
    "         in_table          = 'memory' + os.sep + 'tempTable'\n",
    "        ,out_feature_class = fgdb + os.sep + fc\n",
    "        ,x_field           = longname\n",
    "        ,y_field           = latname\n",
    "        ,coordinate_system = arcpy.SpatialReference(4269)\n",
    "    );\n",
    "    arcpy.Delete_management('memory' + os.sep + 'tempTable');\n",
    "    return True;\n",
    "\n",
    "def fmtext(infc,fieldname,fieldlength):\n",
    "    fm = arcpy.FieldMap();\n",
    "    fm.addInputField(infc,fieldname);\n",
    "    nf = fm.outputField;\n",
    "    nf.type = 'Text';\n",
    "    nf.length = fieldlength;\n",
    "    fm.outputField = nf;\n",
    "    return fm;\n",
    "\n",
    "def fmint(infc,fieldname):\n",
    "    fm = arcpy.FieldMap();\n",
    "    fm.addInputField(infc,fieldname);\n",
    "    nf = fm.outputField;\n",
    "    nf.type = 'Integer';\n",
    "    fm.outputField = nf;\n",
    "    return fm;\n",
    "\n",
    "def fmdouble(infc,fieldname):\n",
    "    fm = arcpy.FieldMap();\n",
    "    fm.addInputField(infc,fieldname);\n",
    "    nf = fm.outputField;\n",
    "    nf.type = 'Double';\n",
    "    fm.outputField = nf;\n",
    "    return fm;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download COOP_STATIONS_TO_USE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  converting to NAD83 points\n",
      "  add quotes to start and end fields\n",
      "  calculating year count\n",
      "  adding indexes\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/coop_stations_to_use.csv\"\n",
    "fc  = 'COOP_STATIONS_TO_USE';\n",
    "\n",
    "tmptab = arcpy.env.scratchFolder + os.sep + 'tempTable.csv';\n",
    "z = downloadtab(url,tmptab);\n",
    "  \n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_id',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_name',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'state',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date',255));\n",
    "fms.addFieldMap(fmdouble(tmptab,'latitude'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'longitude'));\n",
    "fms.addFieldMap(fmtext  (tmptab,'in_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'break_with_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'network',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date_to_use',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date_to_use',255));\n",
    "\n",
    "z = tab2fc(tmptab,fgdb,fc,'longitude','latitude',fms);\n",
    "\n",
    "print(\"  add quotes to start and end fields\");\n",
    "cb_cleanDate = \"\"\"\n",
    "def cleanDate(pin):\n",
    "    (mm,dd,yyyy) = pin.split('/');\n",
    "    if mm in ['1','2','3','4','5','6','7','8','9']:\n",
    "       mm = '0' + mm;\n",
    "    if dd in ['1','2','3','4','5','6','7','8','9']:\n",
    "       dd = '0' + dd;\n",
    "    return \"'\" + yyyy + \"/\" + mm + \"/\" + dd + \"'\";\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'start_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_clean'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'start_date_clean'\n",
    "    ,expression      = \"cleanDate(!start_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'end_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_clean'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'end_date_clean'\n",
    "    ,expression      = \"cleanDate(!end_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'start_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_to_use_clean'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'start_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!start_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'end_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_to_use_clean'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'end_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!end_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "print(\"  calculating year count\");\n",
    "cb_yearCount = \"\"\"\n",
    "import datetime;\n",
    "def yearCount(pstart,pend):\n",
    "    d1 = datetime.datetime.strptime(pstart,\"%m/%d/%Y\");\n",
    "    d2 = datetime.datetime.strptime(pend  ,\"%m/%d/%Y\");\n",
    "    yr = round((d2 - d1).days / 365);\n",
    "    return yr + 0.0;\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'year_count'\n",
    "    ,field_type   = 'Double'\n",
    "    ,field_alias  = 'year_count'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'year_count'\n",
    "    ,expression      = 'yearCount(!start_date_to_use!,!end_date_to_use!)'\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_yearCount\n",
    ");\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "arcpy.management.AddIndex(\n",
    "     in_table      = fgdb + os.sep + fc\n",
    "    ,fields        = 'station_id'\n",
    "    ,index_name    = 'station_id_IDX'\n",
    ");\n",
    "\n",
    "print(\"DONE\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download ISD_STATIONS_TO_USE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  converting to NAD83 points\n",
      "  add quotes to start and end fields\n",
      "  calculating year count\n",
      "  adding indexes\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/isd_stations_to_use.csv\"\n",
    "fc  = 'ISD_STATIONS_TO_USE';\n",
    "\n",
    "tmptab = arcpy.env.scratchFolder + os.sep + 'tempTable.csv';\n",
    "z = downloadtab(url,tmptab);\n",
    "\n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_id',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_name',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'state',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date',255));\n",
    "fms.addFieldMap(fmdouble(tmptab,'latitude'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'longitude'));\n",
    "fms.addFieldMap(fmtext  (tmptab,'in_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'break_with_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'network',255));\n",
    "    \n",
    "z = tab2fc(tmptab,fgdb,fc,'longitude','latitude',fms);\n",
    "\n",
    "print(\"  add quotes to start and end fields\");\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'start_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_clean'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'start_date_clean'\n",
    "    ,expression      = \"cleanDate(!start_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'end_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_clean'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'end_date_clean'\n",
    "    ,expression      = \"cleanDate(!end_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "print(\"  calculating year count\");\n",
    "arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'year_count'\n",
    "    ,field_type   = 'Double'\n",
    "    ,field_alias  = 'year_count'\n",
    ");\n",
    "\n",
    "arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'year_count'\n",
    "    ,expression      = 'yearCount(!start_date!,!end_date!)'\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_yearCount\n",
    ");\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'station_id'\n",
    "    ,index_name = 'station_id_IDX'\n",
    ");\n",
    "\n",
    "print(\"DONE\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
