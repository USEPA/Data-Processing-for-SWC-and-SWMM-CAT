{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Gather Source Datasets\n",
    "\n",
    "Purpose: Download and stage required datasets into the project **source** geodatabase.  \n",
    "\n",
    "Current list of resources:\n",
    "\n",
    "- [CRWU_CREAT_Grid_Projections](https://services.arcgis.com/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Grid_Projections/FeatureServer/0) from EPA Geoplatform\n",
    "- [CRWU_CREAT_Historic_Climate_Stations](https://services.arcgis.com/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Historic_Climate_Stations/FeatureServer/0) from EPA Geoplatform\n",
    "- [COOP_STATIONS_TO_USE](https://github.com/barrc/get_ncei/blob/main/src/coop_stations_to_use.csv) from barrc GitHub\n",
    "- [ISD_STATIONS_TO_USE](https://github.com/barrc/get_ncei/blob/main/src/isd_stations_to_use.csv) from barrc Github\n",
    "- [Census States](https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/State_County/MapServer/0) from US Census Tigerweb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Step 10: Gather Source Datasets\n",
      "  using existing source workspace\n"
     ]
    }
   ],
   "source": [
    "print(\"Executing Step 10: Gather Source Datasets\");\n",
    "\n",
    "import arcpy,os,http.client,json,requests;\n",
    "\n",
    "# Verify or Create Source filegeodatabase\n",
    "fgdb = os.getcwd() + os.sep + 'source.gdb';\n",
    "\n",
    "if not arcpy.Exists(fgdb):\n",
    "    print(\"  creating new source workspace\");\n",
    "    arcpy.CreateFileGDB_management(\n",
    "         os.path.dirname(fgdb)\n",
    "        ,os.path.basename(fgdb)\n",
    "    );\n",
    "else:\n",
    "    print(\"  using existing source workspace\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.010: Scrape AGS \n",
    "\n",
    "Reusable function to scrape an ArcGIS Online resource into a local file geodatabase.\n",
    "Note some online resources (namely Census) have additional download limits beyond the stated maxRecordCount.\n",
    "Using a smaller forcelimit value will usually work around this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_ags(host,path,fgdb,fc,forcelimit=None):\n",
    "    \n",
    "    if arcpy.Exists(fgdb + os.sep + fc):\n",
    "        arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "        \n",
    "    headers = {\"Content-type\": \"application/x-www-form-urlencoded\", \"Accept\": \"text/plain\"};\n",
    "    conn = http.client.HTTPSConnection(host);\n",
    "    conn.request(\"POST\",path,\"f=json\",headers);\n",
    "    response = conn.getresponse();\n",
    "    data = response.read();\n",
    "    json_data = json.loads(data);\n",
    "    if not 'currentVersion' in json_data:\n",
    "        raise ValueError(\"Error, unable to query https://\" + host + path);\n",
    "    extraction_amount = json_data['maxRecordCount'];\n",
    "    if forcelimit is not None and forcelimit < extraction_amount:\n",
    "        extraction_amount = forcelimit;\n",
    "    where = \"1=1\";\n",
    "    params = \"where={}&returnIdsOnly=true&returnGeometry=false&f=json\".format(where);\n",
    "    conn = http.client.HTTPSConnection(host);\n",
    "    conn.request(\"POST\",path + \"/query\",params,headers);\n",
    "    response = conn.getresponse();\n",
    "    data = response.read();\n",
    "    json_data = json.loads(data);\n",
    "    ary_oid   = sorted(json_data['objectIds']);\n",
    "    oid_name  = json_data['objectIdFieldName'];\n",
    "    oid_count = len(ary_oid);\n",
    "    \n",
    "    initial_hit = True;\n",
    "    counter = 0;\n",
    "    while counter <= oid_count - 1:\n",
    "        if counter + extraction_amount > oid_count - 1:\n",
    "            int_max = oid_count - 1;\n",
    "        else:\n",
    "            int_max = counter + extraction_amount - 1;\n",
    "        where = oid_name + ' >= ' + str(ary_oid[counter]) + ' AND ' + oid_name + ' <= ' + str(ary_oid[int_max]);\n",
    "        print(\"  pulling records where \" + where);\n",
    "        fields = \"*\";\n",
    "        params = \"where={}&outFields={}&returnGeometry=true&outSR=4269&f=json\".format(where, fields);\n",
    "        conn = http.client.HTTPSConnection(host);\n",
    "        conn.request(\"POST\",path + \"/query\",params,headers);\n",
    "        response = conn.getresponse();\n",
    "        data = response.read(); \n",
    "        json_data = json.loads(data);\n",
    "        ef = arcpy.AsShape(json_data,True);\n",
    "        if initial_hit:\n",
    "            arcpy.management.CopyFeatures(ef,fgdb + os.sep + fc)\n",
    "            initial_hit = False;\n",
    "        else:\n",
    "            arcpy.Append_management(ef,fgdb + os.sep + fc,\"NO_TEST\");\n",
    "        counter += extraction_amount;\n",
    "        \n",
    "    conn.close(); \n",
    "    del conn;\n",
    "    print(\"  Scrape complete.\");\n",
    "    return True;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.020: Download CRWU_CREAT_Grid_Projections from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 2000\n",
      "  pulling records where OBJECTID >= 2001 AND OBJECTID <= 4000\n",
      "  pulling records where OBJECTID >= 4001 AND OBJECTID <= 6000\n",
      "  pulling records where OBJECTID >= 6001 AND OBJECTID <= 8000\n",
      "  pulling records where OBJECTID >= 8001 AND OBJECTID <= 10000\n",
      "  pulling records where OBJECTID >= 10001 AND OBJECTID <= 12000\n",
      "  pulling records where OBJECTID >= 12001 AND OBJECTID <= 14000\n",
      "  pulling records where OBJECTID >= 14001 AND OBJECTID <= 16000\n",
      "  pulling records where OBJECTID >= 16001 AND OBJECTID <= 18000\n",
      "  pulling records where OBJECTID >= 18001 AND OBJECTID <= 20000\n",
      "  pulling records where OBJECTID >= 20001 AND OBJECTID <= 22000\n",
      "  pulling records where OBJECTID >= 22001 AND OBJECTID <= 24000\n",
      "  pulling records where OBJECTID >= 24001 AND OBJECTID <= 24743\n",
      "  Scrape complete.\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Grid_Projections/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Grid_Projections\";\n",
    "\n",
    "if arcpy.Exists(fgdb + os.sep + fc):\n",
    "    arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "\n",
    "z = scrape_ags(host,path,fgdb,fc);\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'CREAT_ID'\n",
    "    ,index_name = 'CREAT_ID_IDX'\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'GRIDCODE'\n",
    "    ,index_name = 'GRIDCODE_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.030: Download CRWU_CREAT_Historic_Climate_Stations from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 2000\n",
      "  pulling records where OBJECTID >= 2001 AND OBJECTID <= 4000\n",
      "  pulling records where OBJECTID >= 4001 AND OBJECTID <= 6000\n",
      "  pulling records where OBJECTID >= 6001 AND OBJECTID <= 8000\n",
      "  pulling records where OBJECTID >= 8001 AND OBJECTID <= 10000\n",
      "  pulling records where OBJECTID >= 10001 AND OBJECTID <= 11165\n",
      "  Scrape complete.\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Historic_Climate_Stations/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Historic_Climate_Stations\";\n",
    "\n",
    "if arcpy.Exists(fgdb + os.sep + fc):\n",
    "    arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "\n",
    "z = scrape_ags(host,path,fgdb,fc);\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'CLIMATE_STATION_PK_ID'\n",
    "    ,index_name = 'CLIMATE_STATION_PK_ID_IDX'\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'NOAA_STATION_ID'\n",
    "    ,index_name = 'NOAA_STATION_ID_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.040: Tab Downloaders\n",
    "\n",
    "Reusable functions to download and import csv or tab delimited text into local filegeodatabase \n",
    "using optional custom fieldmappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadtab(url,filename):\n",
    "    if arcpy.Exists(filename):\n",
    "        arcpy.Delete_management(filename);\n",
    "    print(\"  downloading file\");\n",
    "    with open(filename,'wb') as f,requests.get(url,stream=True) as r:\n",
    "        for line in r.iter_lines():\n",
    "            f.write(line + '\\n'.encode());\n",
    "    return True;\n",
    "    \n",
    "def tab2fc(filename,fgdb,fc,longname,latname,field_mapping=None):\n",
    "    \n",
    "    if arcpy.Exists('memory' + os.sep + 'tempTable'):\n",
    "        arcpy.Delete_management('memory' + os.sep + 'tempTable');\n",
    "  \n",
    "    print(\"  loading to table\");\n",
    "    arcpy.TableToTable_conversion(\n",
    "         in_rows       = filename\n",
    "        ,out_path      = 'memory'\n",
    "        ,out_name      = 'tempTable'\n",
    "        ,field_mapping = field_mapping\n",
    "    );\n",
    "    \n",
    "    if arcpy.Exists(fgdb + os.sep + fc):\n",
    "        arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "        \n",
    "    print(\"  converting to NAD83 points\");\n",
    "    arcpy.management.XYTableToPoint(\n",
    "         in_table          = 'memory' + os.sep + 'tempTable'\n",
    "        ,out_feature_class = fgdb + os.sep + fc\n",
    "        ,x_field           = longname\n",
    "        ,y_field           = latname\n",
    "        ,coordinate_system = arcpy.SpatialReference(4269)\n",
    "    );\n",
    "    \n",
    "    arcpy.Delete_management('memory' + os.sep + 'tempTable');\n",
    "    return True;\n",
    "\n",
    "def fmtext(infc,fieldname,fieldlength):\n",
    "    fm = arcpy.FieldMap();\n",
    "    fm.addInputField(infc,fieldname);\n",
    "    nf = fm.outputField;\n",
    "    nf.type = 'Text';\n",
    "    nf.length = fieldlength;\n",
    "    fm.outputField = nf;\n",
    "    return fm;\n",
    "\n",
    "def fmint(infc,fieldname):\n",
    "    fm = arcpy.FieldMap();\n",
    "    fm.addInputField(infc,fieldname);\n",
    "    nf = fm.outputField;\n",
    "    nf.type = 'Integer';\n",
    "    fm.outputField = nf;\n",
    "    return fm;\n",
    "\n",
    "def fmdouble(infc,fieldname):\n",
    "    fm = arcpy.FieldMap();\n",
    "    fm.addInputField(infc,fieldname);\n",
    "    nf = fm.outputField;\n",
    "    nf.type = 'Double';\n",
    "    fm.outputField = nf;\n",
    "    return fm;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.050: Download COOP_STATIONS_TO_USE dataset from barrc GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  converting to NAD83 points\n",
      "  add quotes to start and end fields\n",
      "  calculating year count\n",
      "  adding indexes\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/coop_stations_to_use.csv\"\n",
    "fc  = 'COOP_STATIONS_TO_USE';\n",
    "\n",
    "tmptab = arcpy.env.scratchFolder + os.sep + 'tempTable.csv';\n",
    "z = downloadtab(url,tmptab);\n",
    "  \n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_id',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_name',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'state',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date',255));\n",
    "fms.addFieldMap(fmdouble(tmptab,'latitude'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'longitude'));\n",
    "fms.addFieldMap(fmtext  (tmptab,'in_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'break_with_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'network',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date_to_use',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date_to_use',255));\n",
    "\n",
    "z = tab2fc(tmptab,fgdb,fc,'longitude','latitude',fms);\n",
    "\n",
    "print(\"  add quotes to start and end fields\");\n",
    "cb_cleanDate = \"\"\"\n",
    "def cleanDate(pin):\n",
    "    (mm,dd,yyyy) = pin.split('/');\n",
    "    if mm in ['1','2','3','4','5','6','7','8','9']:\n",
    "       mm = '0' + mm;\n",
    "    if dd in ['1','2','3','4','5','6','7','8','9']:\n",
    "       dd = '0' + dd;\n",
    "    return \"'\" + yyyy + \"/\" + mm + \"/\" + dd + \"'\";\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'start_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'start_date_clean'\n",
    "    ,expression      = \"cleanDate(!start_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'end_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'end_date_clean'\n",
    "    ,expression      = \"cleanDate(!end_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'start_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_to_use_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'start_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!start_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'end_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_to_use_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'end_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!end_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "print(\"  calculating year count\");\n",
    "cb_yearCount = \"\"\"\n",
    "import datetime;\n",
    "def yearCount(pstart,pend):\n",
    "    d1 = datetime.datetime.strptime(pstart,\"%m/%d/%Y\");\n",
    "    d2 = datetime.datetime.strptime(pend  ,\"%m/%d/%Y\");\n",
    "    yr = round((d2 - d1).days / 365);\n",
    "    return yr + 0.0;\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'year_count'\n",
    "    ,field_type   = 'Double'\n",
    "    ,field_alias  = 'year_count'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'year_count'\n",
    "    ,expression      = 'yearCount(!start_date_to_use!,!end_date_to_use!)'\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_yearCount\n",
    ");\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table      = fgdb + os.sep + fc\n",
    "    ,fields        = 'station_id'\n",
    "    ,index_name    = 'station_id_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.060: Download ISD_STATIONS_TO_USE dataset from barrc GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  converting to NAD83 points\n",
      "  add quotes to start and end fields\n",
      "  calculating year count\n",
      "  adding indexes\n",
      "Wall time: 7.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/isd_stations_to_use.csv\"\n",
    "fc  = 'ISD_STATIONS_TO_USE';\n",
    "\n",
    "tmptab = arcpy.env.scratchFolder + os.sep + 'tempTable.csv';\n",
    "z = downloadtab(url,tmptab);\n",
    "\n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_id',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_name',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'state',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date',255));\n",
    "fms.addFieldMap(fmdouble(tmptab,'latitude'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'longitude'));\n",
    "fms.addFieldMap(fmtext  (tmptab,'in_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'break_with_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'network',255));\n",
    "    \n",
    "z = tab2fc(tmptab,fgdb,fc,'longitude','latitude',fms);\n",
    "\n",
    "print(\"  add quotes to start and end fields\");\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'start_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'start_date_clean'\n",
    "    ,expression      = \"cleanDate(!start_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'end_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'end_date_clean'\n",
    "    ,expression      = \"cleanDate(!end_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "print(\"  calculating year count\");\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = fgdb + os.sep + fc\n",
    "    ,field_name   = 'year_count'\n",
    "    ,field_type   = 'Double'\n",
    "    ,field_alias  = 'year_count'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = fgdb + os.sep + fc\n",
    "    ,field           = 'year_count'\n",
    "    ,expression      = 'yearCount(!start_date!,!end_date!)'\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_yearCount\n",
    ");\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'station_id'\n",
    "    ,index_name = 'station_id_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.070: Download US Census Tigerweb 2020 State Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 5\n",
      "  pulling records where OBJECTID >= 6 AND OBJECTID <= 10\n",
      "  pulling records where OBJECTID >= 11 AND OBJECTID <= 15\n",
      "  pulling records where OBJECTID >= 16 AND OBJECTID <= 20\n",
      "  pulling records where OBJECTID >= 21 AND OBJECTID <= 25\n",
      "  pulling records where OBJECTID >= 26 AND OBJECTID <= 30\n",
      "  pulling records where OBJECTID >= 31 AND OBJECTID <= 35\n",
      "  pulling records where OBJECTID >= 36 AND OBJECTID <= 40\n",
      "  pulling records where OBJECTID >= 41 AND OBJECTID <= 45\n",
      "  pulling records where OBJECTID >= 46 AND OBJECTID <= 50\n",
      "  pulling records where OBJECTID >= 51 AND OBJECTID <= 55\n",
      "  pulling records where OBJECTID >= 56 AND OBJECTID <= 56\n",
      "  Scrape complete.\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Note tigerweb will timeout if all state-equivalent records are requested in one go.\n",
    "# Setting the forcelimit value to 5 records at once works around the problem.\n",
    "\n",
    "host = \"tigerweb.geo.census.gov\";\n",
    "path = \"/arcgis/rest/services/TIGERweb/State_County/MapServer/0\";\n",
    "fc   = \"census_states\";\n",
    "\n",
    "if arcpy.Exists(fgdb + os.sep + fc):\n",
    "    arcpy.Delete_management(fgdb + os.sep + fc);\n",
    "\n",
    "z = scrape_ags(host,path,fgdb,fc,5);\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = fgdb + os.sep + fc\n",
    "    ,fields     = 'GEOID'\n",
    "    ,index_name = 'GEOID_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.080: Review results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Grid Projections : 24743\n",
      "  Historic Stations: 11165\n",
      "  COOP Stations    : 1851\n",
      "  ISD Stations     : 3293\n",
      "  Tigerweb States  : 56\n",
      " \n"
     ]
    }
   ],
   "source": [
    "grid = fgdb + os.sep + 'CRWU_CREAT_Grid_Projections';\n",
    "grid_cnt = arcpy.GetCount_management(grid)[0];\n",
    "hist = fgdb + os.sep + 'CRWU_CREAT_Historic_Climate_Stations';\n",
    "hist_cnt = arcpy.GetCount_management(hist)[0];\n",
    "coop = fgdb + os.sep + 'COOP_STATIONS_TO_USE';\n",
    "coop_cnt = arcpy.GetCount_management(coop)[0];\n",
    "isd  = fgdb + os.sep + 'ISD_STATIONS_TO_USE';\n",
    "isd_cnt = arcpy.GetCount_management(isd)[0];\n",
    "states  = fgdb + os.sep + 'census_states';\n",
    "states_cnt = arcpy.GetCount_management(states)[0];\n",
    "\n",
    "print(\"  Grid Projections : \" + str(grid_cnt));\n",
    "print(\"  Historic Stations: \" + str(hist_cnt));\n",
    "print(\"  COOP Stations    : \" + str(coop_cnt));\n",
    "print(\"  ISD Stations     : \" + str(isd_cnt));\n",
    "print(\"  Tigerweb States  : \" + str(states_cnt));\n",
    "print(\" \");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
