{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Gather Source Datasets\n",
    "\n",
    "Purpose: Download and stage required datasets into the project **source** geodatabase.  \n",
    "\n",
    "Current list of resources:\n",
    "\n",
    "- [CRWU_CREAT_Grid_Projections](https://services.arcgis.com/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Grid_Projections/FeatureServer/0) from EPA Geoplatform\n",
    "- [CRWU_CREAT_Historic_Climate_Stations](https://services.arcgis.com/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Historic_Climate_Stations/FeatureServer/0) from EPA Geoplatform\n",
    "- [COOP_STATIONS_TO_USE](https://github.com/barrc/get_ncei/blob/main/src/coop_stations_to_use.csv) from barrc GitHub\n",
    "- [ISD_STATIONS_TO_USE](https://github.com/barrc/get_ncei/blob/main/src/isd_stations_to_use.csv) from barrc Github\n",
    "- [TEMPORAL_DIST_FILE](https://github.com/barrc/extreme_events/blob/main/temporal_dist_file.txt) from barrc GitHub\n",
    "- [Census States](https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/State_County/MapServer/0) from US Census Tigerweb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Step 10: Gather Source Datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Executing Step 10: Gather Source Datasets\");\n",
    "\n",
    "# Load common utilities\n",
    "%run ./swcutil.ipynb\n",
    "\n",
    "rez = swc_resources();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.010: Download CRWU_CREAT_Grid_Projections from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0a18169b7a46abbfc321fdbbb19af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 2000\n",
      "  pulling records where OBJECTID >= 2001 AND OBJECTID <= 4000\n",
      "  pulling records where OBJECTID >= 4001 AND OBJECTID <= 6000\n",
      "  pulling records where OBJECTID >= 6001 AND OBJECTID <= 8000\n",
      "  pulling records where OBJECTID >= 8001 AND OBJECTID <= 10000\n",
      "  pulling records where OBJECTID >= 10001 AND OBJECTID <= 12000\n",
      "  pulling records where OBJECTID >= 12001 AND OBJECTID <= 14000\n",
      "  pulling records where OBJECTID >= 14001 AND OBJECTID <= 16000\n",
      "  pulling records where OBJECTID >= 16001 AND OBJECTID <= 18000\n",
      "  pulling records where OBJECTID >= 18001 AND OBJECTID <= 20000\n",
      "  pulling records where OBJECTID >= 20001 AND OBJECTID <= 22000\n",
      "  pulling records where OBJECTID >= 22001 AND OBJECTID <= 24000\n",
      "  pulling records where OBJECTID >= 24001 AND OBJECTID <= 24743\n",
      "  Scrape complete.\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f = IntProgress(min=0,max=3);\n",
    "display(f);\n",
    "\n",
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Grid_Projections/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Grid_Projections\";\n",
    "\n",
    "if arcpy.Exists(rez['source'] + os.sep + fc):\n",
    "    arcpy.Delete_management(rez['source'] + os.sep + fc);\n",
    "f.value +=1;\n",
    "\n",
    "z = scrape_ags(host,path,rez['source'],fc);\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'CREAT_ID'\n",
    "    ,index_name = 'CREAT_ID_IDX'\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'GRIDCODE'\n",
    "    ,index_name = 'GRIDCODE_IDX'\n",
    ");\n",
    "f.value +=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.020: Download CRWU_CREAT_Historic_Climate_Stations from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2816f37ca18e4ccbad9a89392a3e50dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 2000\n",
      "  pulling records where OBJECTID >= 2001 AND OBJECTID <= 4000\n",
      "  pulling records where OBJECTID >= 4001 AND OBJECTID <= 6000\n",
      "  pulling records where OBJECTID >= 6001 AND OBJECTID <= 8000\n",
      "  pulling records where OBJECTID >= 8001 AND OBJECTID <= 10000\n",
      "  pulling records where OBJECTID >= 10001 AND OBJECTID <= 11165\n",
      "  Scrape complete.\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f = IntProgress(min=0,max=3);\n",
    "display(f);\n",
    "\n",
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Historic_Climate_Stations/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Historic_Climate_Stations\";\n",
    "\n",
    "if arcpy.Exists(rez['source'] + os.sep + fc):\n",
    "    arcpy.Delete_management(rez['source'] + os.sep + fc);\n",
    "f.value +=1;\n",
    "\n",
    "z = scrape_ags(host,path,rez['source'],fc);\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'CLIMATE_STATION_PK_ID'\n",
    "    ,index_name = 'CLIMATE_STATION_PK_ID_IDX'\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'NOAA_STATION_ID'\n",
    "    ,index_name = 'NOAA_STATION_ID_IDX'\n",
    ");\n",
    "f.value +=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.030: Download COOP_STATIONS_TO_USE dataset from barrc GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c3aa48cca249b2b40e5ba2aab6f686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  converting to NAD83 points\n",
      "  add quotes to start and end fields\n",
      "  calculating year count\n",
      "  adding indexes\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f = IntProgress(min=0,max=8);\n",
    "display(f);\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/coop_stations_to_use.csv\"\n",
    "fc  = 'COOP_STATIONS_TO_USE';\n",
    "\n",
    "tmptab = rez['qa'] + os.sep + 'coop_stations_to_use.csv';\n",
    "z = downloadtab(url,tmptab);\n",
    "f.value +=1;\n",
    "\n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_id',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_name',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'state',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date',255));\n",
    "fms.addFieldMap(fmdouble(tmptab,'latitude'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'longitude'));\n",
    "fms.addFieldMap(fmtext  (tmptab,'in_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'break_with_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'network',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date_to_use',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date_to_use',255));\n",
    "f.value +=1;\n",
    "\n",
    "z = tab2fc(tmptab,rez['source'],fc,'longitude','latitude',fms);\n",
    "f.value +=1;\n",
    "\n",
    "print(\"  add quotes to start and end fields\");\n",
    "cb_cleanDate = \"\"\"\n",
    "def cleanDate(pin):\n",
    "    (mm,dd,yyyy) = pin.split('/');\n",
    "    if mm in ['1','2','3','4','5','6','7','8','9']:\n",
    "       mm = '0' + mm;\n",
    "    if dd in ['1','2','3','4','5','6','7','8','9']:\n",
    "       dd = '0' + dd;\n",
    "    return \"'\" + yyyy + \"/\" + mm + \"/\" + dd + \"'\";\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'start_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'start_date_clean'\n",
    "    ,expression      = \"cleanDate(!start_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'end_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'end_date_clean'\n",
    "    ,expression      = \"cleanDate(!end_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'start_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_to_use_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'start_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!start_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'end_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_to_use_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'end_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!end_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "print(\"  calculating year count\");\n",
    "cb_yearCount = \"\"\"\n",
    "import datetime;\n",
    "def yearCount(pstart,pend):\n",
    "    d1 = datetime.datetime.strptime(pstart,\"%m/%d/%Y\");\n",
    "    d2 = datetime.datetime.strptime(pend  ,\"%m/%d/%Y\");\n",
    "    yr = round((d2 - d1).days / 365);\n",
    "    return yr + 0.0;\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'year_count'\n",
    "    ,field_type   = 'Double'\n",
    "    ,field_alias  = 'year_count'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'year_count'\n",
    "    ,expression      = 'yearCount(!start_date_to_use!,!end_date_to_use!)'\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_yearCount\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table      = rez['source']+ os.sep + fc\n",
    "    ,fields        = 'station_id'\n",
    "    ,index_name    = 'station_id_IDX'\n",
    ");\n",
    "f.value +=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.040: Download ISD_STATIONS_TO_USE dataset from barrc GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a673424156c43aab0ab572f989cc7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  converting to NAD83 points\n",
      "  add quotes to start and end fields\n",
      "  calculating year count\n",
      "  adding indexes\n",
      "Wall time: 9.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f = IntProgress(min=0,max=6);\n",
    "display(f);\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/isd_stations_to_use.csv\"\n",
    "fc  = 'ISD_STATIONS_TO_USE';\n",
    "\n",
    "tmptab = rez['qa'] + os.sep + 'isd_stations_to_use.csv';\n",
    "z = downloadtab(url,tmptab);\n",
    "f.value +=1;\n",
    "\n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_id',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'station_name',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'state',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'start_date',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'end_date',255));\n",
    "fms.addFieldMap(fmdouble(tmptab,'latitude'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'longitude'));\n",
    "fms.addFieldMap(fmtext  (tmptab,'in_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'break_with_basins',255));\n",
    "fms.addFieldMap(fmtext  (tmptab,'network',255));\n",
    "f.value +=1;\n",
    "\n",
    "z = tab2fc(tmptab,rez['source'],fc,'longitude','latitude',fms);\n",
    "f.value +=1;\n",
    "\n",
    "print(\"  add quotes to start and end fields\");\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'start_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'start_date_clean'\n",
    "    ,expression      = \"cleanDate(!start_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'end_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'end_date_clean'\n",
    "    ,expression      = \"cleanDate(!end_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "print(\"  calculating year count\");\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'year_count'\n",
    "    ,field_type   = 'Double'\n",
    "    ,field_alias  = 'year_count'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'year_count'\n",
    "    ,expression      = 'yearCount(!start_date!,!end_date!)'\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_yearCount\n",
    ");\n",
    "f.value +=1;\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'station_id'\n",
    "    ,index_name = 'station_id_IDX'\n",
    ");\n",
    "f.value +=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.050: Download TEMPORAL_DIST_FILE dataset from barrc GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f887fea3ee460e8f763e51ec885fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  adding indexes\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f = IntProgress(min=0,max=3);\n",
    "display(f);\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/extreme_events/main/temporal_dist_file.txt\"\n",
    "fc  = 'TEMPORAL_DIST_FILE';\n",
    "\n",
    "tmptab = rez['qa'] + os.sep + 'temporal_dist_file.tab';\n",
    "z = downloadtab(url,tmptab);\n",
    "f.value +=1;\n",
    "\n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(fmdouble(tmptab,'Time'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'CA_1'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'CA_2'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'CA_3'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'CA_4'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'CA_5'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'CA_6'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'MSE_1'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'MSE_2'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'MSE_3'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'MSE_4'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'MSE_5'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'MSE_6'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NOAA_A'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NOAA_B'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NOAA_C'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NOAA_D'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NRCC_A'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NRCC_B'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NRCC_C'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NRCC_D'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NV_N'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NV_S'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'NV_W'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'SCS_I'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'SCS_IA'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'SCS_II'));\n",
    "fms.addFieldMap(fmdouble(tmptab,'SCS_III'));\n",
    "f.value +=1;\n",
    "\n",
    "z = tab2tab(tmptab,rez['source'],fc,fms);\n",
    "f.value +=1;\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'time'\n",
    "    ,index_name = 'time_IDX'\n",
    ");\n",
    "f.value +=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.060: Download US Census Tigerweb 2020 State Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa18c4aa04549f5bf6fc76f0817e47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pulling records where OBJECTID >= 1 AND OBJECTID <= 5\n",
      "  pulling records where OBJECTID >= 6 AND OBJECTID <= 10\n",
      "  pulling records where OBJECTID >= 11 AND OBJECTID <= 15\n",
      "  pulling records where OBJECTID >= 16 AND OBJECTID <= 20\n",
      "  pulling records where OBJECTID >= 21 AND OBJECTID <= 25\n",
      "  pulling records where OBJECTID >= 26 AND OBJECTID <= 30\n",
      "  pulling records where OBJECTID >= 31 AND OBJECTID <= 35\n",
      "  pulling records where OBJECTID >= 36 AND OBJECTID <= 40\n",
      "  pulling records where OBJECTID >= 41 AND OBJECTID <= 45\n",
      "  pulling records where OBJECTID >= 46 AND OBJECTID <= 50\n",
      "  pulling records where OBJECTID >= 51 AND OBJECTID <= 55\n",
      "  pulling records where OBJECTID >= 56 AND OBJECTID <= 56\n",
      "  Scrape complete.\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Note tigerweb will timeout if all state-equivalent records are requested in one go.\n",
    "# Setting the forcelimit value to 5 records at once works around the problem.\n",
    "\n",
    "f = IntProgress(min=0,max=1);\n",
    "display(f);\n",
    "\n",
    "host = \"tigerweb.geo.census.gov\";\n",
    "path = \"/arcgis/rest/services/TIGERweb/State_County/MapServer/0\";\n",
    "fc   = \"census_states\";\n",
    "\n",
    "if arcpy.Exists(rez['source'] + os.sep + fc):\n",
    "    arcpy.Delete_management(rez['source'] + os.sep + fc);\n",
    "\n",
    "z = scrape_ags(host,path,rez['source'],fc,5);\n",
    "f.value +=1;\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'GEOID'\n",
    "    ,index_name = 'GEOID_IDX'\n",
    ");\n",
    "f.value +=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.080: Review results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Grid Projections : 24743\n",
      "  Historic Stations: 11165\n",
      "  COOP Stations    : 1851\n",
      "  ISD Stations     : 3293\n",
      "  Tigerweb States  : 56\n",
      " \n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid = rez['source']  + os.sep + 'CRWU_CREAT_Grid_Projections';\n",
    "grid_cnt = arcpy.GetCount_management(grid)[0];\n",
    "hist = rez['source']  + os.sep + 'CRWU_CREAT_Historic_Climate_Stations';\n",
    "hist_cnt = arcpy.GetCount_management(hist)[0];\n",
    "coop = rez['source']  + os.sep + 'COOP_STATIONS_TO_USE';\n",
    "coop_cnt = arcpy.GetCount_management(coop)[0];\n",
    "isd  = rez['source']  + os.sep + 'ISD_STATIONS_TO_USE';\n",
    "isd_cnt = arcpy.GetCount_management(isd)[0];\n",
    "tdf  = rez['source']  + os.sep + 'TEMPORAL_DIST_FILE';\n",
    "tdf_cnt = arcpy.GetCount_management(tdf)[0];\n",
    "states  = rez['source'] + os.sep + 'census_states';\n",
    "states_cnt = arcpy.GetCount_management(states)[0];\n",
    "\n",
    "print(\"  Grid Projections : \" + str(grid_cnt));\n",
    "print(\"  Historic Stations: \" + str(hist_cnt));\n",
    "print(\"  COOP Stations    : \" + str(coop_cnt));\n",
    "print(\"  ISD Stations     : \" + str(isd_cnt));\n",
    "print(\"  Tigerweb States  : \" + str(states_cnt));\n",
    "print(\" \");\n",
    "\n",
    "nw = datetime.datetime.now();\n",
    "with open(rez['qa'] + os.sep + 'step10qa.txt',\"w\") as out:\n",
    "    out.write(\"Step 10 QA Review\\n\");\n",
    "    out.write(datetime.datetime.now().isoformat() + \"\\n\");\n",
    "    out.write(\"Grid Projections Loaded: \" + str(grid_cnt) + \"\\n\");\n",
    "    out.write(\"Historic Stations Loaded: \" + str(hist_cnt) + \"\\n\");\n",
    "    out.write(\"COOP Stations Loaded: \" + str(coop_cnt) + \"\\n\");\n",
    "    out.write(\"ISD Stations Loaded: \" + str(isd_cnt) + \"\\n\");\n",
    "    out.write(\"Temp Dist File Records Loaded: \" + str(tdf_cnt) + \"\\n\");\n",
    "    out.write(\"Tigerweb States Loaded: \" + str(states_cnt) + \"\\n\");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
