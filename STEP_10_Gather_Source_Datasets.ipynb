{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Gather Source Datasets\n",
    "\n",
    "Purpose: Download and stage required datasets into the project **source** geodatabase.  \n",
    "\n",
    "Current list of resources:\n",
    "\n",
    "- [CRWU_CREAT_Grid_Projections](https://services.arcgis.com/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Grid_Projections/FeatureServer/0) from EPA Geoplatform\n",
    "- [CRWU_CREAT_Historic_Climate_Stations](https://services.arcgis.com/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Historic_Climate_Stations/FeatureServer/0) from EPA Geoplatform\n",
    "- [COOP_STATIONS_TO_USE](https://github.com/barrc/get_ncei/blob/main/src/coop_stations_to_use.csv) from barrc GitHub\n",
    "- [ISD_STATIONS_TO_USE](https://github.com/barrc/get_ncei/blob/main/src/isd_stations_to_use.csv) from barrc Github\n",
    "- [TEMPORAL_DIST_FILE](https://github.com/barrc/extreme_events/blob/main/temporal_dist_file.txt) from barrc GitHub\n",
    "- [Census States](https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/State_County/MapServer/0) from US Census Tigerweb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Step 10: Gather Source Datasets\n"
     ]
    }
   ],
   "source": [
    "import arcpy;\n",
    "import os,sys;\n",
    "import csv,importlib;\n",
    "\n",
    "print(\"Executing Step 10: Gather Source Datasets\");\n",
    "\n",
    "import swc_resources;\n",
    "importlib.reload(swc_resources);\n",
    "rez = swc_resources.rez();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.010: Download CRWU_CREAT_Grid_Projections from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading CRWU_CREAT_Grid_Projections\n",
      "  Adding indexes\n",
      "  Complete.\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Grid_Projections/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Grid_Projections\";\n",
    "\n",
    "if arcpy.Exists(rez['source'] + os.sep + fc):\n",
    "    arcpy.Delete_management(rez['source'] + os.sep + fc);\n",
    "\n",
    "print(\"  Downloading \" + fc);\n",
    "z = swc_resources.scrape_ags(host,path,rez['source'],fc);\n",
    "\n",
    "print(\"  Adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'CREAT_ID'\n",
    "    ,index_name = 'CREAT_ID_IDX'\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'GRIDCODE'\n",
    "    ,index_name = 'GRIDCODE_IDX'\n",
    ");\n",
    "\n",
    "print(\"  Complete.\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.020: Download CRWU_CREAT_Historic_Climate_Stations from EPA Geoplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading CRWU_CREAT_Historic_Climate_Stations\n",
      "  Adding indexes\n",
      "  Complete.\n",
      "Wall time: 9.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "host = \"services.arcgis.com\";\n",
    "path = \"/cJ9YHowT8TU7DUyn/ArcGIS/rest/services/CRWU_CREAT_Historic_Climate_Stations/FeatureServer/0\";\n",
    "fc   = \"CRWU_CREAT_Historic_Climate_Stations\";\n",
    "\n",
    "if arcpy.Exists(rez['source'] + os.sep + fc):\n",
    "    arcpy.Delete_management(rez['source'] + os.sep + fc);\n",
    "\n",
    "print(\"  Downloading \" + fc);\n",
    "z = swc_resources.scrape_ags(host,path,rez['source'],fc);\n",
    "\n",
    "print(\"  Adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'CLIMATE_STATION_PK_ID'\n",
    "    ,index_name = 'CLIMATE_STATION_PK_ID_IDX'\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'NOAA_STATION_ID'\n",
    "    ,index_name = 'NOAA_STATION_ID_IDX'\n",
    ");\n",
    "\n",
    "print(\"  Complete.\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.030: Download COOP_STATIONS_TO_USE dataset from barrc GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  converting to NAD83 points\n",
      "  check for missing stationIDs\n",
      "  add quotes to start and end fields\n",
      "  calculating year count\n",
      "  adding indexes\n",
      "Wall time: 8.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/coop_stations_to_use.csv\"\n",
    "fc  = 'COOP_STATIONS_TO_USE';\n",
    "\n",
    "tmptab = rez['qa'] + os.sep + 'coop_stations_to_use.csv';\n",
    "z = swc_resources.downloadtab(url,tmptab);\n",
    "\n",
    "fmscoop = arcpy.FieldMappings();\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'station_id',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'station_name',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'state',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'start_date',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'end_date',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmdouble(tmptab,'latitude'));\n",
    "fmscoop.addFieldMap(swc_resources.fmdouble(tmptab,'longitude'));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'in_basins',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'break_with_basins',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'network',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'start_date_to_use',255));\n",
    "fmscoop.addFieldMap(swc_resources.fmtext  (tmptab,'end_date_to_use',255));\n",
    "\n",
    "z = swc_resources.tab2fc(tmptab,rez['source'],fc,'longitude','latitude',fmscoop);\n",
    "\n",
    "print(\"  check for missing stationIDs\");\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'station_id'\n",
    "    ,expression      = \"injectID(!station_id!,!OBJECTID!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = \"\"\"\n",
    "def injectID(pin,oid):\n",
    "    if pin is None:\n",
    "        return 'COOP' + str(oid);\n",
    "    else:\n",
    "        return pin;\n",
    "\"\"\");\n",
    "\n",
    "print(\"  add quotes to start and end fields\");\n",
    "cb_cleanDate = \"\"\"\n",
    "def cleanDate(pin):\n",
    "    (mm,dd,yyyy) = pin.split('/');\n",
    "    if mm in ['1','2','3','4','5','6','7','8','9']:\n",
    "       mm = '0' + mm;\n",
    "    if dd in ['1','2','3','4','5','6','7','8','9']:\n",
    "       dd = '0' + dd;\n",
    "    return \"'\" + yyyy + \"/\" + mm + \"/\" + dd + \"'\";\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'start_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'start_date_clean'\n",
    "    ,expression      = \"cleanDate(!start_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'end_date_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'end_date_clean'\n",
    "    ,expression      = \"cleanDate(!end_date!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'start_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'start_date_to_use_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'start_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!start_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'end_date_to_use_clean'\n",
    "    ,field_type   = 'Text'\n",
    "    ,field_length = 255\n",
    "    ,field_alias  = 'end_date_to_use_clean'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'end_date_to_use_clean'\n",
    "    ,expression      = \"cleanDate(!end_date_to_use!)\"\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_cleanDate\n",
    ");\n",
    "\n",
    "print(\"  calculating year count\");\n",
    "cb_yearCount = \"\"\"\n",
    "import datetime;\n",
    "def yearCount(pstart,pend):\n",
    "    d1 = datetime.datetime.strptime(pstart,\"%m/%d/%Y\");\n",
    "    d2 = datetime.datetime.strptime(pend  ,\"%m/%d/%Y\");\n",
    "    yr = round((d2 - d1).days / 365);\n",
    "    return yr + 0.0;\n",
    "    \n",
    "\"\"\";\n",
    "\n",
    "z = arcpy.management.AddField(\n",
    "     in_table     = rez['source'] + os.sep + fc\n",
    "    ,field_name   = 'year_count'\n",
    "    ,field_type   = 'Double'\n",
    "    ,field_alias  = 'year_count'\n",
    ");\n",
    "\n",
    "z = arcpy.management.CalculateField(\n",
    "     in_table        = rez['source'] + os.sep + fc\n",
    "    ,field           = 'year_count'\n",
    "    ,expression      = 'yearCount(!start_date_to_use!,!end_date_to_use!)'\n",
    "    ,expression_type = 'PYTHON3'\n",
    "    ,code_block      = cb_yearCount\n",
    ");\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table      = rez['source']+ os.sep + fc\n",
    "    ,fields        = 'station_id'\n",
    "    ,index_name    = 'station_id_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.040: Download ISD_STATIONS_TO_USE dataset from barrc GitHub repository\n",
    "\n",
    "Note originally this ISD processing step was coded similarly to the above cell processing the COOP csv file using the built-in arcpy TableToTable tools.  Even though the logic provides an expressed fieldmapping stating that the station id is textual in nature, __sometimes__ the tool would choke on the final 15 records (those having an ID beginning with 'A').  But just sometimes.  It is not a problem I have been able to reliably reproduce.  The best solution is to just \"don't do that\" and instead load the csv file using the Python csv library and an arcpy DA cursor.  I remain uncertain as to why this is the case but suspect the UTF-8 characters in the ISD csv file __might__ have something to do with it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  Adding indexes\n",
      "  Loading table from file\n",
      "  Complete\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/get_ncei/master/src/isd_stations_to_use.csv\"\n",
    "fc  = 'ISD_STATIONS_TO_USE';\n",
    "\n",
    "outcsv10040 = rez['qa'] + os.sep + 'isd_stations_to_use.csv';\n",
    "z = swc_resources.downloadtab(url,outcsv10040);\n",
    "\n",
    "output10040 = rez['source'] + os.sep + fc;\n",
    "if arcpy.Exists(output10040):\n",
    "    arcpy.Delete_management(output10040);\n",
    "\n",
    "arcpy.CreateFeatureclass_management(\n",
    "     out_path      = os.path.dirname(output10040)\n",
    "    ,out_name      = os.path.basename(output10040)\n",
    "    ,geometry_type = \"POINT\"\n",
    "    ,has_m         = \"DISABLED\"\n",
    "    ,has_z         = \"DISABLED\"\n",
    "    ,spatial_reference = arcpy.SpatialReference(4269) \n",
    ");\n",
    "\n",
    "arcpy.management.AddFields(\n",
    "     in_table          = output10040\n",
    "    ,field_description = [\n",
    "         ['station_id'       ,'TEXT'  ,'Station ID'       ,255]\n",
    "        ,['station_name'     ,'TEXT'  ,'Station Name'     ,255]\n",
    "        ,['state'            ,'TEXT'  ,'State'            ,255]\n",
    "        ,['start_date'       ,'TEXT'  ,'Start Date'       ,255]\n",
    "        ,['end_date'         ,'TEXT'  ,'End Date'         ,255]\n",
    "        ,['latitude'         ,'DOUBLE','Latitude'         ,255]\n",
    "        ,['longitude'        ,'DOUBLE','Longitude'        ,255]\n",
    "        ,['in_basins'        ,'TEXT'  ,'In Basins'        ,255]\n",
    "        ,['break_with_basins','TEXT'  ,'Break With Basins',255]\n",
    "        ,['network'          ,'TEXT'  ,'Network'          ,255]\n",
    "        ,['start_date_clean' ,'TEXT'  ,'Start Date Clean' ,255]\n",
    "        ,['end_date_clean'   ,'TEXT'  ,'End Date Clean'   ,255]\n",
    "        ,['year_count'       ,'DOUBLE','Year Count'           ]\n",
    "    ]\n",
    ");\n",
    "\n",
    "print(\"  Adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = output10040\n",
    "    ,fields     = 'Station_id'\n",
    "    ,index_name = 'StationId_IDX'\n",
    ");\n",
    "\n",
    "fldsout = [\n",
    "     'station_id'\n",
    "    ,'station_name'\n",
    "    ,'state'\n",
    "    ,'start_date'\n",
    "    ,'end_date'\n",
    "    ,'latitude'\n",
    "    ,'longitude'\n",
    "    ,'in_basins'\n",
    "    ,'break_with_basins'\n",
    "    ,'network'\n",
    "    ,'start_date_clean'\n",
    "    ,'end_date_clean'\n",
    "    ,'year_count'\n",
    "    ,'SHAPE@'\n",
    "];\n",
    "\n",
    "print(\"  Loading table from file\")\n",
    "with arcpy.da.InsertCursor(\n",
    "     in_table    = output10040\n",
    "    ,field_names = fldsout\n",
    ") as outcur:\n",
    "\n",
    "    with open(outcsv10040,newline='',encoding='utf-8') as tdf:\n",
    "        next(tdf);\n",
    "        \n",
    "        reader = csv.reader(tdf,delimiter=',');\n",
    "        for row in reader:\n",
    "            \n",
    "            start_date        = datetime.datetime.strptime(row[3] ,\"%Y-%m-%d %H:%M:%S\");\n",
    "            end_date          = datetime.datetime.strptime(row[4] ,\"%Y-%m-%d %H:%M:%S\");\n",
    "            \n",
    "            year_count = round((end_date - start_date).days / 365);\n",
    "            year_count = year_count + 0.0;\n",
    "            \n",
    "            lat = float(row[5]);\n",
    "            lng = float(row[6]);\n",
    "            \n",
    "            pt = arcpy.Point();\n",
    "            pt.X = lng;\n",
    "            pt.Y = lat;\n",
    "            \n",
    "            if lat == 0 or lng == 0:\n",
    "                pass;\n",
    "            else:\n",
    "                outcur.insertRow((\n",
    "                     row[0]\n",
    "                    ,row[1]\n",
    "                    ,row[2]\n",
    "                    ,row[3]\n",
    "                    ,row[4]\n",
    "                    ,lat\n",
    "                    ,lng\n",
    "                    ,row[7]\n",
    "                    ,row[8]\n",
    "                    ,row[9]\n",
    "                    ,\"'\" + start_date.strftime('%Y/%m/%d') + \"'\"\n",
    "                    ,\"'\" + end_date.strftime('%Y/%m/%d') + \"'\"\n",
    "                    ,year_count\n",
    "                    ,arcpy.PointGeometry(pt)\n",
    "                ));\n",
    "\n",
    "print(\"  Complete\");\n",
    "del outcsv10040,output10040;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.050: Download TEMPORAL_DIST_FILE dataset from barrc GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  downloading file\n",
      "  loading to table\n",
      "  adding indexes\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/barrc/extreme_events/main/temporal_dist_file.txt\"\n",
    "fc  = 'TEMPORAL_DIST_FILE';\n",
    "\n",
    "tmptab = rez['qa'] + os.sep + 'temporal_dist_file.tab';\n",
    "z = swc_resources.downloadtab(url,tmptab);\n",
    "\n",
    "fms = arcpy.FieldMappings();\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'Time'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'CA_1'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'CA_2'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'CA_3'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'CA_4'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'CA_5'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'CA_6'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'MSE_1'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'MSE_2'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'MSE_3'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'MSE_4'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'MSE_5'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'MSE_6'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NOAA_A'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NOAA_B'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NOAA_C'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NOAA_D'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NRCC_A'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NRCC_B'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NRCC_C'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NRCC_D'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NV_N'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NV_S'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'NV_W'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'SCS_I'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'SCS_IA'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'SCS_II'));\n",
    "fms.addFieldMap(swc_resources.fmdouble(tmptab,'SCS_III'));\n",
    "\n",
    "z = swc_resources.tab2tab(tmptab,rez['source'],fc,fms);\n",
    "\n",
    "print(\"  adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'time'\n",
    "    ,index_name = 'time_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.060: Download US Census Tigerweb 2020 State Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading census_states\n",
      "  Adding indexes\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Note tigerweb will timeout if all state-equivalent records are requested in one go.\n",
    "# Setting the forcelimit value to 5 records at once works around the problem.\n",
    "\n",
    "host = \"tigerweb.geo.census.gov\";\n",
    "path = \"/arcgis/rest/services/TIGERweb/State_County/MapServer/0\";\n",
    "fc   = \"census_states\";\n",
    "\n",
    "if arcpy.Exists(rez['source'] + os.sep + fc):\n",
    "    arcpy.Delete_management(rez['source'] + os.sep + fc);\n",
    "\n",
    "print(\"  Downloading \" + fc);\n",
    "z = swc_resources.scrape_ags(host,path,rez['source'],fc,5);\n",
    "\n",
    "print(\"  Adding indexes\");\n",
    "z = arcpy.management.AddIndex(\n",
    "     in_table   = rez['source'] + os.sep + fc\n",
    "    ,fields     = 'GEOID'\n",
    "    ,index_name = 'GEOID_IDX'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.070: Review and QA\n",
    "\n",
    "QA Products:\n",
    "\n",
    "1. flat files saved to **qa** folder\n",
    "2. counts saved to **step10qa.txt**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Grid Projections : 24743\n",
      "  Historic Stations: 11165\n",
      "  COOP Stations    : 1851\n",
      "  ISD Stations     : 3293\n",
      "  Tigerweb States  : 56\n",
      " \n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid = rez['source']  + os.sep + 'CRWU_CREAT_Grid_Projections';\n",
    "grid_cnt = arcpy.GetCount_management(grid)[0];\n",
    "hist = rez['source']  + os.sep + 'CRWU_CREAT_Historic_Climate_Stations';\n",
    "hist_cnt = arcpy.GetCount_management(hist)[0];\n",
    "coop = rez['source']  + os.sep + 'COOP_STATIONS_TO_USE';\n",
    "coop_cnt = arcpy.GetCount_management(coop)[0];\n",
    "isd  = rez['source']  + os.sep + 'ISD_STATIONS_TO_USE';\n",
    "isd_cnt = arcpy.GetCount_management(isd)[0];\n",
    "tdf  = rez['source']  + os.sep + 'TEMPORAL_DIST_FILE';\n",
    "tdf_cnt = arcpy.GetCount_management(tdf)[0];\n",
    "states  = rez['source'] + os.sep + 'census_states';\n",
    "states_cnt = arcpy.GetCount_management(states)[0];\n",
    "\n",
    "print(\"  Grid Projections : \" + str(grid_cnt));\n",
    "print(\"  Historic Stations: \" + str(hist_cnt));\n",
    "print(\"  COOP Stations    : \" + str(coop_cnt));\n",
    "print(\"  ISD Stations     : \" + str(isd_cnt));\n",
    "print(\"  Tigerweb States  : \" + str(states_cnt));\n",
    "print(\" \");\n",
    "\n",
    "nw = datetime.datetime.now();\n",
    "with open(rez['qa'] + os.sep + 'step10qa.txt',\"w\") as out:\n",
    "    out.write(\"Step 10 QA Review\\n\");\n",
    "    out.write(datetime.datetime.now().isoformat() + \"\\n\");\n",
    "    out.write(\"Grid Projections Loaded: \" + str(grid_cnt) + \"\\n\");\n",
    "    out.write(\"Historic Stations Loaded: \" + str(hist_cnt) + \"\\n\");\n",
    "    out.write(\"COOP Stations Loaded: \" + str(coop_cnt) + \"\\n\");\n",
    "    out.write(\"ISD Stations Loaded: \" + str(isd_cnt) + \"\\n\");\n",
    "    out.write(\"Temp Dist File Records Loaded: \" + str(tdf_cnt) + \"\\n\");\n",
    "    out.write(\"Tigerweb States Loaded: \" + str(states_cnt) + \"\\n\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
